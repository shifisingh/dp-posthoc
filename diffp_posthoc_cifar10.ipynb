{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 602,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# get 10,000 length dataset subset \n",
    "dataset = torchvision.datasets.CIFAR10(root=\"cifar\", train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "subset_length = 10000\n",
    "train_loader = DataLoader(dataset, batch_size=32)\n",
    "dataset_mini = Subset(dataset, range(subset_length))\n",
    "trainloader_mini = DataLoader(dataset_mini, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 603,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biased dataset, need to implement short circuiting prevention in order to use \n",
    "\n",
    "# Define the desired total number of samples\n",
    "total_samples = subset_length\n",
    "\n",
    "# Define the percentages for each class\n",
    "percentage_from_class = {\n",
    "    0: 0.4,\n",
    "    1: 0.2,\n",
    "    # Remaining classes will get an equal share\n",
    "}\n",
    "\n",
    "# Calculate the remaining percentage for classes 2-9\n",
    "remaining_percentage = 1.0 - sum(percentage_from_class.values())\n",
    "\n",
    "# Distribute the remaining percentage evenly among classes 2-9\n",
    "remaining_percentage_per_class = remaining_percentage / (10 - len(percentage_from_class))\n",
    "\n",
    "# Calculate the number of samples to take from each class\n",
    "subset_indices = []\n",
    "\n",
    "for class_label, percentage in percentage_from_class.items():\n",
    "    class_indices = [i for i, (_, label) in enumerate(dataset) if label == class_label]\n",
    "    num_samples_class = int(total_samples * percentage)\n",
    "    subset_indices.extend(class_indices[:num_samples_class])\n",
    "\n",
    "# Distribute the remaining samples to classes 2-9\n",
    "for class_label in range(2, 10):\n",
    "    class_indices = [i for i, (_, label) in enumerate(dataset) if label == class_label]\n",
    "    num_samples_class = int(total_samples * remaining_percentage_per_class)\n",
    "    subset_indices.extend(class_indices[:num_samples_class])\n",
    "\n",
    "# Ensure the total number of samples is exactly 10,000\n",
    "subset_indices = subset_indices[:total_samples]\n",
    "\n",
    "# Create the Subset with the specified indices\n",
    "dataset_mini_biased = Subset(dataset, subset_indices)\n",
    "\n",
    "# Create DataLoader\n",
    "trainloader_mini_biased = DataLoader(dataset_mini_biased, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: airplane\n",
      "1: automobile\n",
      "2: bird\n",
      "3: cat\n",
      "4: deer\n",
      "5: dog\n",
      "6: frog\n",
      "7: horse\n",
      "8: ship\n",
      "9: truck\n"
     ]
    }
   ],
   "source": [
    "# get mapping of label ints to label names \n",
    "import pickle\n",
    "\n",
    "batches_meta_file_path = 'cifar/cifar-10-batches-py/batches.meta'\n",
    "\n",
    "with open(batches_meta_file_path, 'rb') as f:\n",
    "    batches_meta_data = pickle.load(f)\n",
    "\n",
    "label_names = batches_meta_data.get('label_names', None)\n",
    "\n",
    "for i in range(len(label_names)):\n",
    "    print(str(i) + ': ' +label_names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 604,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: 4000 datapoints\n",
      "Class 1: 2000 datapoints\n",
      "Class 2: 499 datapoints\n",
      "Class 3: 499 datapoints\n",
      "Class 4: 499 datapoints\n",
      "Class 5: 499 datapoints\n",
      "Class 6: 499 datapoints\n",
      "Class 7: 499 datapoints\n",
      "Class 8: 499 datapoints\n",
      "Class 9: 499 datapoints\n"
     ]
    }
   ],
   "source": [
    "# Count datapoints per class\n",
    "class_counts = {i: 0 for i in range(10)}  \n",
    "\n",
    "for data in trainloader_mini_biased:\n",
    "    _, labels = data\n",
    "    for label in labels:\n",
    "        class_counts[label.item()] += 1\n",
    "\n",
    "# Print the counts\n",
    "for class_label, count in class_counts.items():\n",
    "    print(f\"Class {class_label}: {count} datapoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non Differentially Private Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet model, adjusted for 32x32 CIFAR images images\n",
    "model = torchvision.models.resnet18()\n",
    "\n",
    "model.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "n_features = model.fc.in_features\n",
    "n_classes = 10\n",
    "model.fc = torch.nn.Linear(n_features, n_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accuracy before training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 9.44%\n",
      "Accuracy for label airplane: 4.26%\n",
      "Accuracy for label automobile: 0.04%\n",
      "Accuracy for label bird: 15.18%\n",
      "Accuracy for label cat: 3.72%\n",
      "Accuracy for label deer: 39.08%\n",
      "Accuracy for label dog: 0.04%\n",
      "Accuracy for label frog: 1.92%\n",
      "Accuracy for label horse: 23.36%\n",
      "Accuracy for label ship: 5.06%\n",
      "Accuracy for label truck: 1.76%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Ensure model in training mode\n",
    "model.train()\n",
    "\n",
    "# Initialize variables\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "class_correct = [0] * n_classes  \n",
    "class_total = [0] * n_classes\n",
    "\n",
    "# Evaluate the model on the entire dataset\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        # Update per-class statistics\n",
    "        for i in range(n_classes):\n",
    "            class_correct[i] += ((predicted == labels) & (labels == i)).sum().item()\n",
    "            class_total[i] += (labels == i).sum().item()\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f\"Accuracy on the training set: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate accuracy per label\n",
    "for i in range(n_classes):\n",
    "    class_acc = class_correct[i] / class_total[i] if class_total[i] != 0 else 0\n",
    "    print(f\"Accuracy for label {label_names[i]}: {class_acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save untrained model \n",
    "torch.save(model.state_dict(), 'model_untrained_1.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Non Differentially Private Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training \n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "def train_one_epoch():\n",
    "    running_loss = 0.0\n",
    "    last_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(trainloader_mini):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:\n",
    "            last_loss = running_loss / 10  # loss per batch\n",
    "            print(f\"batch {i+1} loss: {last_loss}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "batch 10 loss: 0.770458270329982\n",
      "batch 20 loss: 0.001341010733449366\n",
      "batch 30 loss: 8.196803973987698e-05\n",
      "batch 40 loss: 3.87634940125281e-05\n",
      "batch 50 loss: 3.3866098056023476e-05\n",
      "batch 60 loss: 2.212325816799421e-05\n",
      "batch 70 loss: 2.179072344006272e-05\n",
      "batch 80 loss: 2.217123455920955e-05\n",
      "batch 90 loss: 2.4013922666199505e-05\n",
      "batch 100 loss: 2.6201683067483827e-05\n",
      "batch 110 loss: 2.147280783901806e-05\n",
      "batch 120 loss: 2.7335498998581897e-05\n",
      "batch 130 loss: 5.890845071939839\n",
      "batch 140 loss: 0.7714707814000576\n",
      "batch 150 loss: 1.5679627509257444e-06\n",
      "batch 160 loss: 7.63683996041209e-08\n",
      "batch 170 loss: 1.415609804933382e-08\n",
      "batch 180 loss: 2.458690602225033e-08\n",
      "batch 190 loss: 5.595492754876607\n",
      "batch 200 loss: 8.370921320654451\n",
      "batch 210 loss: 10.264572607411537\n",
      "batch 220 loss: 3.7014779657125474\n",
      "batch 230 loss: 8.558609676361083\n",
      "batch 240 loss: 5.457883715629578\n",
      "batch 250 loss: 3.901036334037781\n",
      "batch 260 loss: 5.847078609466553\n",
      "batch 270 loss: 3.7020266890525817\n",
      "batch 280 loss: 3.5645959615707397\n",
      "batch 290 loss: 4.278479528427124\n",
      "batch 300 loss: 3.342396783828735\n",
      "batch 310 loss: 3.5824498414993284\n",
      "Epoch: 2\n",
      "batch 10 loss: 7.156985092163086\n",
      "batch 20 loss: 4.012574696540833\n",
      "batch 30 loss: 1.2088549315929413\n",
      "batch 40 loss: 0.20151695124804975\n",
      "batch 50 loss: 0.03677479550242424\n",
      "batch 60 loss: 0.01388082685880363\n",
      "batch 70 loss: 0.009194513875991106\n",
      "batch 80 loss: 0.007299374346621335\n",
      "batch 90 loss: 0.006075069680809975\n",
      "batch 100 loss: 0.005823344155214727\n",
      "batch 110 loss: 0.0037007460952736436\n",
      "batch 120 loss: 0.004185009002685547\n",
      "batch 130 loss: 5.146804247994441\n",
      "batch 140 loss: 5.154441666603089\n",
      "batch 150 loss: 0.8954387813806534\n",
      "batch 160 loss: 0.10926509946584702\n",
      "batch 170 loss: 0.03364861514419317\n",
      "batch 180 loss: 0.01373451966792345\n",
      "batch 190 loss: 1.9421565629309043\n",
      "batch 200 loss: 4.643486475944519\n",
      "batch 210 loss: 3.4141581416130067\n",
      "batch 220 loss: 2.399581503868103\n",
      "batch 230 loss: 3.457565498352051\n",
      "batch 240 loss: 3.120037889480591\n",
      "batch 250 loss: 2.47363862991333\n",
      "batch 260 loss: 3.6486297845840454\n",
      "batch 270 loss: 2.9538613319396974\n",
      "batch 280 loss: 2.8648200035095215\n",
      "batch 290 loss: 3.2789311528205873\n",
      "batch 300 loss: 3.0557506322860717\n",
      "batch 310 loss: 3.288049077987671\n",
      "Epoch: 3\n",
      "batch 10 loss: 3.5678717851638795\n",
      "batch 20 loss: 2.3046592473983765\n",
      "batch 30 loss: 0.9238739967346191\n",
      "batch 40 loss: 0.17785419821739196\n",
      "batch 50 loss: 0.03521037194877863\n",
      "batch 60 loss: 0.014740843512117862\n",
      "batch 70 loss: 0.00964690139517188\n",
      "batch 80 loss: 0.009713883791118861\n",
      "batch 90 loss: 0.007041516015306115\n",
      "batch 100 loss: 0.007228133035823703\n",
      "batch 110 loss: 0.004361950792372227\n",
      "batch 120 loss: 0.004545965138822794\n",
      "batch 130 loss: 4.159390336368233\n",
      "batch 140 loss: 3.823463463783264\n",
      "batch 150 loss: 1.0208422064781189\n",
      "batch 160 loss: 0.2027005858719349\n",
      "batch 170 loss: 0.06319151110947133\n",
      "batch 180 loss: 0.0259689730592072\n",
      "batch 190 loss: 1.707704006275162\n",
      "batch 200 loss: 4.723724269866944\n",
      "batch 210 loss: 3.544266152381897\n",
      "batch 220 loss: 2.730323839187622\n",
      "batch 230 loss: 3.106009912490845\n",
      "batch 240 loss: 3.055879998207092\n",
      "batch 250 loss: 2.7218090057373048\n",
      "batch 260 loss: 3.1570775270462037\n",
      "batch 270 loss: 2.7775866985321045\n",
      "batch 280 loss: 2.860080099105835\n",
      "batch 290 loss: 3.132130336761475\n",
      "batch 300 loss: 2.8082319021224977\n",
      "batch 310 loss: 2.852906060218811\n",
      "Epoch: 4\n",
      "batch 10 loss: 3.162375831604004\n",
      "batch 20 loss: 2.3121376037597656\n",
      "batch 30 loss: 1.4471633553504943\n",
      "batch 40 loss: 0.7913690626621246\n",
      "batch 50 loss: 0.3450652778148651\n",
      "batch 60 loss: 0.13095419257879257\n",
      "batch 70 loss: 0.07974995635449886\n",
      "batch 80 loss: 0.05439800526946783\n",
      "batch 90 loss: 0.025766899390146137\n",
      "batch 100 loss: 0.026019371766597032\n",
      "batch 110 loss: 0.014056370523758233\n",
      "batch 120 loss: 0.012386224558576941\n",
      "batch 130 loss: 3.6183278128970415\n",
      "batch 140 loss: 4.166597962379456\n",
      "batch 150 loss: 1.8224425435066223\n",
      "batch 160 loss: 0.5512551702558994\n",
      "batch 170 loss: 0.20296425521373748\n",
      "batch 180 loss: 0.08627231530845166\n",
      "batch 190 loss: 1.716333106532693\n",
      "batch 200 loss: 4.76207332611084\n",
      "batch 210 loss: 3.7570991039276125\n",
      "batch 220 loss: 2.867665100097656\n",
      "batch 230 loss: 3.2229054450988768\n",
      "batch 240 loss: 3.0310953855514526\n",
      "batch 250 loss: 2.6457611083984376\n",
      "batch 260 loss: 3.1555396556854247\n",
      "batch 270 loss: 2.9343934535980223\n",
      "batch 280 loss: 2.8178901195526125\n",
      "batch 290 loss: 3.0839242696762086\n",
      "batch 300 loss: 2.7675134897232057\n",
      "batch 310 loss: 2.8981293439865112\n",
      "Epoch: 5\n",
      "batch 10 loss: 3.1127103090286257\n",
      "batch 20 loss: 2.225069010257721\n",
      "batch 30 loss: 1.3805493712425232\n",
      "batch 40 loss: 0.8552153050899506\n",
      "batch 50 loss: 0.362827804684639\n",
      "batch 60 loss: 0.27002752274274827\n",
      "batch 70 loss: 0.1649767454713583\n",
      "batch 80 loss: 0.09743965342640877\n",
      "batch 90 loss: 0.048281542398035525\n",
      "batch 100 loss: 0.054553561564534905\n",
      "batch 110 loss: 0.03028933717869222\n",
      "batch 120 loss: 0.023145432118326426\n",
      "batch 130 loss: 3.2403404716402293\n",
      "batch 140 loss: 4.192961406707764\n",
      "batch 150 loss: 2.2286595940589904\n",
      "batch 160 loss: 1.0048516392707825\n",
      "batch 170 loss: 0.4960875630378723\n",
      "batch 180 loss: 0.24190503172576427\n",
      "batch 190 loss: 1.380232723429799\n",
      "batch 200 loss: 4.625591564178467\n",
      "batch 210 loss: 3.7967061519622805\n",
      "batch 220 loss: 3.2352394580841066\n",
      "batch 230 loss: 3.2770992040634157\n",
      "batch 240 loss: 2.960633873939514\n",
      "batch 250 loss: 2.8340561151504517\n",
      "batch 260 loss: 3.051281547546387\n",
      "batch 270 loss: 2.775636100769043\n",
      "batch 280 loss: 2.7466013431549072\n",
      "batch 290 loss: 2.9230705738067626\n",
      "batch 300 loss: 2.726525378227234\n",
      "batch 310 loss: 2.8385039567947388\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "for i in range(EPOCHS):\n",
    "    print(f\"Epoch: {i+1}\")\n",
    "    train_one_epoch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "def calc_accuracy(model):\n",
    "    # Ensure model in eval mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize variables\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "    class_correct = [0] * n_classes  \n",
    "    class_total = [0] * n_classes\n",
    "    \n",
    "    # Evaluate the model on the entire dataset\n",
    "    with torch.no_grad():\n",
    "        for data in train_loader:\n",
    "            images, labels = data\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_samples += labels.size(0)\n",
    "            correct_predictions += (predicted == labels).sum().item()\n",
    "    \n",
    "            # Update per-class statistics\n",
    "            for i in range(n_classes):\n",
    "                class_correct[i] += ((predicted == labels) & (labels == i)).sum().item()\n",
    "                class_total[i] += (labels == i).sum().item()\n",
    "    \n",
    "    # Calculate overall accuracy\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    print(f\"Accuracy on the training set: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    # Calculate accuracy per label\n",
    "    for i in range(n_classes):\n",
    "        class_acc = class_correct[i] / class_total[i] if class_total[i] != 0 else 0\n",
    "        print(f\"Accuracy for label {label_names[i]}: {class_acc * 100:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 9.64%\n",
      "Accuracy for label airplane: 0.00%\n",
      "Accuracy for label automobile: 0.00%\n",
      "Accuracy for label bird: 0.00%\n",
      "Accuracy for label cat: 0.00%\n",
      "Accuracy for label deer: 0.00%\n",
      "Accuracy for label dog: 0.00%\n",
      "Accuracy for label frog: 0.00%\n",
      "Accuracy for label horse: 0.00%\n",
      "Accuracy for label ship: 93.34%\n",
      "Accuracy for label truck: 3.02%\n"
     ]
    }
   ],
   "source": [
    "calc_accuracy(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# function which takes in a model and outputs two dictionaries which store \n",
    "# which datapoints model predicted correctly and incorrectly \n",
    "def create_predictions_dictionaries(model):\n",
    "    correct_predictions_dict = {label: [] for label in range(10)}\n",
    "    incorrect_predictions_dict = {label: [] for label in range(10)}\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (inputs, targets) in enumerate(train_loader):\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "            for j in range(len(predicted)):\n",
    "                label = int(targets[j])\n",
    "                if predicted[j] == targets[j]:\n",
    "                    correct_predictions_dict[label].append(i * train_loader.batch_size + j)\n",
    "                else:\n",
    "                    incorrect_predictions_dict[label].append(i * train_loader.batch_size + j)\n",
    "\n",
    "    return correct_predictions_dict, incorrect_predictions_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_trained_biased_1.pt')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying a Sigular Model Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32161\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# set a random seet\n",
    "np.random.seed(38) \n",
    "\n",
    "# Choose a random index from the training set\n",
    "random_index = np.random.randint(len(dataset))\n",
    "\n",
    "print(random_index)\n",
    "# Get the corresponding image and label\n",
    "random_image, true_label = dataset[47373]\n",
    "\n",
    "# Add a batch dimension to the image\n",
    "random_image = random_image.unsqueeze(0)\n",
    "\n",
    "# set back to eval mode\n",
    "model3b.eval()\n",
    "\n",
    "# Make a prediction for the random image\n",
    "with torch.no_grad():\n",
    "    predicted_scores = model1b(random_image)\n",
    "\n",
    "# Get the predicted label\n",
    "predicted_label = torch.argmax(predicted_scores).item()\n",
    "\n",
    "# Display the image\n",
    "random_image_np = random_image.squeeze().numpy()\n",
    "\n",
    "plt.imshow(np.transpose(random_image_np, (1, 2, 0)))\n",
    "plt.title(f\"True Label: {true_label}, Predicted Label: {predicted_label}\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 855,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import segmentation, color\n",
    "from skimage.io import imshow\n",
    "\n",
    "\n",
    "# takes in np image of C X H X W\n",
    "# returns image where boundaries are superimposed, H X W X C\n",
    "\n",
    "def create_segmentation(image_np):\n",
    "    # Higher value of compactness give more weight to space proximity,\n",
    "    # making superpixel shapes more square/cubic. should choose values on log scale\n",
    "    # i.e. .01, .1, 10, 100...\n",
    "    segments = segmentation.slic(image_np, n_segments=5, compactness=.01, channel_axis=0)\n",
    "    masked_image =  segmentation.mark_boundaries(np.transpose(image_np, (1, 2, 0)), segments)\n",
    "\n",
    "    return masked_image\n",
    "\n",
    "    \n",
    "def create_fm(image_np):\n",
    "\n",
    "    segments = segmentation.slic(image_np, n_segments=5, compactness=.01, channel_axis=0)\n",
    "    feature_map = np.zeros_like(image_np[0])  # Assuming image_np is in the shape (C, H, W)\n",
    "    \n",
    "    for segment_value in np.unique(segments):\n",
    "        mask = segments == segment_value\n",
    "        feature_map[mask] = segment_value\n",
    "\n",
    "    return feature_map\n",
    "\n",
    "\n",
    "create_fm(random_image_np)\n",
    "# Display the original image \n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(np.transpose(random_image_np, (1, 2, 0)))\n",
    "plt.title('Original Image')\n",
    "\n",
    "# Display the image with superpixel boundaries\n",
    "plt.subplot(1, 2, 2)\n",
    "seg = create_segmentation(random_image_np)\n",
    "plt.imshow(seg)\n",
    "plt.title('Image with Superpixel Boundaries')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 856,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Display the image with superpixel boundaries\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "fm = create_fm(random_image_np)\n",
    "plt.imshow(fm)\n",
    "plt.title('Feature Map')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lime Explanation Function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from captum.attr import LayerIntegratedGradients, LayerGradientXActivation\n",
    "from captum.attr import visualization as viz\n",
    "from lime import lime_image\n",
    "from skimage.segmentation import mark_boundaries\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import VOCSegmentation\n",
    "import torchvision.transforms as T\n",
    "from captum.attr._core.lime import get_exp_kernel_similarity_function\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from captum.attr import visualization as viz\n",
    "from captum.attr import Lime, LimeBase\n",
    "from captum._utils.models.linear_model import SkLearnLinearRegression, SkLearnLasso\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create segmentation mask\n",
    "tensimg = torch.tensor(random_image_np)\n",
    "seg_mask = torch.tensor(create_segmentation(random_image_np))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "airplane (0): 0.7259\n",
      "deer (4): 0.1318\n",
      "frog (6): 0.0758\n",
      "truck (9): 0.0285\n",
      "bird (2): 0.0207\n"
     ]
    }
   ],
   "source": [
    "# output probabilities of image being classified as \n",
    "# top 'k' categories, with highest probability signifying \n",
    "# the final classification  \n",
    "\n",
    "def create_li(model, img_tens): \n",
    "    outputs = model(img_tens.unsqueeze(0))\n",
    "    output_probs = F.softmax(outputs, dim=1).squeeze(0)\n",
    "    return output_probs.argmax().unsqueeze(0)\n",
    "\n",
    "def probs_of_image(probs, topk=1):\n",
    "    probs, label_indices = torch.topk(probs, topk)\n",
    "    probs = probs.tolist()\n",
    "    label_indices = label_indices.tolist()\n",
    "    for prob, idx in zip(probs, label_indices):\n",
    "        label = label_names[idx]\n",
    "        print(f'{label} ({idx}):', round(prob, 4))\n",
    "        \n",
    "probs_of_image(output_probs, topk=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Lime attribution: 100%|| 3/3 [00:00<00:00,  6.71it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribution range: 0.16320689022541046 to 0.31571778655052185\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# take in model and random image in np array\n",
    "# output lime image explanation heatmap \n",
    "def create_limeimageexp(model, image_np):\n",
    "    image_tens = torch.tensor(image_np)\n",
    "    seg_mask = torch.tensor(create_segmentation(image_np))\n",
    "\n",
    "    outputs = model(image_tens.unsqueeze(0))\n",
    "    output_probs = F.softmax(outputs, dim=1).squeeze(0)\n",
    "    label_idx = output_probs.argmax().unsqueeze(0)\n",
    "\n",
    "    seg_ids = sorted(seg_mask.unique().tolist())\n",
    "\n",
    "    # map segment IDs to feature group IDs\n",
    "    feature_mask = seg_mask.clone()\n",
    "    for i, seg_id in enumerate(seg_ids):\n",
    "        feature_mask[feature_mask == seg_id] = i\n",
    "\n",
    "    feature_mask = torch.tensor(create_fm(image_np), dtype=torch.long)\n",
    "    for i, seg_id in enumerate(seg_ids):\n",
    "        feature_mask[feature_mask == seg_id] = i\n",
    "    \n",
    "    exp_eucl_distance = get_exp_kernel_similarity_function('euclidean', kernel_width=1000)\n",
    "\n",
    "    lr_lime = Lime(\n",
    "        model, \n",
    "        interpretable_model=SkLearnLinearRegression(),  # build-in wrapped sklearn Linear Regression\n",
    "        similarity_func=exp_eucl_distance\n",
    "    )\n",
    "\n",
    "    attrs = lr_lime.attribute(\n",
    "        image_tens.unsqueeze(0),\n",
    "        target=label_idx,\n",
    "        feature_mask=feature_mask,\n",
    "        n_samples=40,\n",
    "        perturbations_per_eval=16,\n",
    "        show_progress=True\n",
    "    ).squeeze(0)\n",
    "    \n",
    "    print('Attribution range:', attrs.min().item(), 'to', attrs.max().item())\n",
    "\n",
    "\n",
    "    viz.visualize_image_attr(\n",
    "        attrs.permute(1, 2, 0).numpy(),  # adjust shape to height, width, channels\n",
    "        method='heat_map',\n",
    "        sign='all',\n",
    "        show_colorbar=True\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differential privacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 835,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "MAX_GRAD_NORM = .1\n",
    "# higher epsilon = higher privact budget = less private model \n",
    "EPSILON = .1\n",
    "DELTA = .0001\n",
    "EPOCHS = 5\n",
    "\n",
    "LR = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 838,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import copy\n",
    "\n",
    "# make a copy of non dp model \n",
    "# for which we will fine tune last layers with dp \n",
    "model_dp = copy.deepcopy(model2)\n",
    "\n",
    "# Create backbone and head\n",
    "backbone_dp = torch.nn.Sequential(*list(model_dp.children())[:-1])\n",
    "head_dp = torch.nn.Sequential(torch.nn.Flatten(), torch.nn.Linear(n_features, n_classes))\n",
    "\n",
    "# Set the backbone to evaluation mode\n",
    "backbone_dp = backbone_dp.eval()\n",
    "\n",
    "# Set the head to training mode\n",
    "head_dp = head_dp.train()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 839,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 10])"
      ]
     },
     "execution_count": 839,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(trainloader_mini_biased))\n",
    "\n",
    "with torch.no_grad():\n",
    "  representation = backbone_dp(x)\n",
    "\n",
    "# quick sanity check\n",
    "head_dp(representation).shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 840,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 840,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "errors = ModuleValidator.validate(head_dp, strict=False)\n",
    "errors[-5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 841,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "head_dp = ModuleValidator.fix(head_dp)\n",
    "ModuleValidator.validate(head_dp, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training  \n",
    "\n",
    "loss_fn_dp = torch.nn.CrossEntropyLoss()\n",
    "optimizer_dp = torch.optim.SGD(head_dp.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 845,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using sigma=3.75 and C=0.1\n"
     ]
    }
   ],
   "source": [
    "# mini dataset privacy engine\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "privacy_engine = PrivacyEngine()\n",
    "\n",
    "head_dp, optimizer_dp, trainloader_mini = privacy_engine.make_private_with_epsilon(\n",
    "    module=head_dp,\n",
    "    optimizer=optimizer_dp,\n",
    "    data_loader=trainloader_mini,\n",
    "    epochs=EPOCHS,\n",
    "    target_epsilon=EPSILON,\n",
    "    target_delta=DELTA,\n",
    "    max_grad_norm=MAX_GRAD_NORM,\n",
    ")\n",
    "\n",
    "print(f\"Using sigma={optimizer_dp.noise_multiplier} and C={MAX_GRAD_NORM}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 846,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train_one_epoch_dp():\n",
    "    running_loss = 0.0\n",
    "    last_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(trainloader_mini):\n",
    "        \n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer_dp.zero_grad()\n",
    "\n",
    "        # Extract features from the backbone\n",
    "        with torch.no_grad():\n",
    "            features = backbone_dp(inputs)\n",
    "\n",
    "        # Make predictions for this batch using the extracted features\n",
    "        outputs = head_dp(features)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn_dp(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights only for head parameters\n",
    "        optimizer_dp.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        if i % 10 == 9:\n",
    "            epsilon = privacy_engine.get_epsilon(DELTA)\n",
    "            last_loss = running_loss / 10  # loss per batch\n",
    "            print(f\"batch {i+1} loss: {last_loss}\")\n",
    "            print(f\"( = {epsilon:.2f},  = {DELTA})\")\n",
    "            running_loss = 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 847,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "batch 10 loss: 2.868224596977234\n",
      "( = 0.01,  = 0.0001)\n",
      "batch 20 loss: 2.857881855964661\n",
      "( = 0.02,  = 0.0001)\n",
      "batch 30 loss: 2.8479529857635497\n",
      "( = 0.02,  = 0.0001)\n",
      "batch 40 loss: 2.820332384109497\n",
      "( = 0.02,  = 0.0001)\n",
      "batch 50 loss: 2.8118637084960936\n",
      "( = 0.02,  = 0.0001)\n",
      "batch 60 loss: 2.7292364835739136\n",
      "( = 0.02,  = 0.0001)\n",
      "batch 70 loss: 2.6890204191207885\n",
      "( = 0.02,  = 0.0001)\n",
      "batch 80 loss: 2.6564183235168457\n",
      "( = 0.02,  = 0.0001)\n",
      "batch 90 loss: 2.7111972093582155\n",
      "( = 0.03,  = 0.0001)\n",
      "batch 100 loss: 2.6722443103790283\n",
      "( = 0.03,  = 0.0001)\n",
      "batch 110 loss: 2.642640805244446\n",
      "( = 0.03,  = 0.0001)\n",
      "batch 120 loss: 2.657654595375061\n",
      "( = 0.03,  = 0.0001)\n",
      "batch 130 loss: 2.621382808685303\n",
      "( = 0.03,  = 0.0001)\n",
      "batch 140 loss: 2.5085468530654906\n",
      "( = 0.03,  = 0.0001)\n",
      "batch 150 loss: 2.5833354711532595\n",
      "( = 0.03,  = 0.0001)\n",
      "batch 160 loss: 2.576019358634949\n",
      "( = 0.03,  = 0.0001)\n",
      "batch 170 loss: 2.474162483215332\n",
      "( = 0.03,  = 0.0001)\n",
      "batch 180 loss: 2.4093706369400025\n",
      "( = 0.03,  = 0.0001)\n",
      "batch 190 loss: 2.3702967882156374\n",
      "( = 0.03,  = 0.0001)\n",
      "batch 200 loss: 2.378913998603821\n",
      "( = 0.04,  = 0.0001)\n",
      "batch 210 loss: 2.352077031135559\n",
      "( = 0.04,  = 0.0001)\n",
      "batch 220 loss: 2.363180327415466\n",
      "( = 0.04,  = 0.0001)\n",
      "batch 230 loss: 2.2717532753944396\n",
      "( = 0.04,  = 0.0001)\n",
      "batch 240 loss: 2.2072885513305662\n",
      "( = 0.04,  = 0.0001)\n",
      "batch 250 loss: 2.3645646810531615\n",
      "( = 0.04,  = 0.0001)\n",
      "batch 260 loss: 2.265969085693359\n",
      "( = 0.04,  = 0.0001)\n",
      "batch 270 loss: 2.3507727146148683\n",
      "( = 0.04,  = 0.0001)\n",
      "batch 280 loss: 2.2790831327438354\n",
      "( = 0.04,  = 0.0001)\n",
      "batch 290 loss: 2.253640055656433\n",
      "( = 0.04,  = 0.0001)\n",
      "batch 300 loss: 2.2451884269714357\n",
      "( = 0.04,  = 0.0001)\n",
      "batch 310 loss: 2.2007555246353148\n",
      "( = 0.04,  = 0.0001)\n",
      "Epoch: 2\n",
      "batch 10 loss: 2.2014651536941527\n",
      "( = 0.04,  = 0.0001)\n",
      "batch 20 loss: 2.113939368724823\n",
      "( = 0.04,  = 0.0001)\n",
      "batch 30 loss: 2.1328665018081665\n",
      "( = 0.04,  = 0.0001)\n",
      "batch 40 loss: 2.1118494272232056\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 50 loss: 2.051712703704834\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 60 loss: 2.032097911834717\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 70 loss: 2.125681519508362\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 80 loss: 2.103993368148804\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 90 loss: 2.0157931566238405\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 100 loss: 2.1172570824623107\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 110 loss: 1.967888879776001\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 120 loss: 2.003887391090393\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 130 loss: 2.054694354534149\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 140 loss: 2.0159719705581667\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 150 loss: 1.996642518043518\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 160 loss: 1.9118756413459779\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 170 loss: 1.9873324394226075\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 180 loss: 1.9208487272262573\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 190 loss: 1.9995381951332092\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 200 loss: 1.9361660480499268\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 210 loss: 1.9855111360549926\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 220 loss: 1.9489133715629579\n",
      "( = 0.05,  = 0.0001)\n",
      "batch 230 loss: 1.920207679271698\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 240 loss: 1.924798321723938\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 250 loss: 1.9365017771720887\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 260 loss: 1.9192304730415344\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 270 loss: 1.904189693927765\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 280 loss: 1.883863663673401\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 290 loss: 1.8908003211021422\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 300 loss: 1.9304597139358521\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 310 loss: 1.9420620679855347\n",
      "( = 0.06,  = 0.0001)\n",
      "Epoch: 3\n",
      "batch 10 loss: 1.8068724989891052\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 20 loss: 1.8970930099487304\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 30 loss: 1.7975736856460571\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 40 loss: 1.7201242446899414\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 50 loss: 1.8928442001342773\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 60 loss: 1.738526463508606\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 70 loss: 1.8480380415916442\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 80 loss: 1.8651424765586853\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 90 loss: 1.7734501361846924\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 100 loss: 1.8055977702140809\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 110 loss: 1.8265007615089417\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 120 loss: 1.8256070375442506\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 130 loss: 1.7910343289375306\n",
      "( = 0.06,  = 0.0001)\n",
      "batch 140 loss: 1.790534007549286\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 150 loss: 1.8198696851730347\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 160 loss: 1.911342167854309\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 170 loss: 1.8046185493469238\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 180 loss: 1.7578663110733033\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 190 loss: 1.7047667503356934\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 200 loss: 1.6691224336624146\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 210 loss: 1.760229766368866\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 220 loss: 1.7775280475616455\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 230 loss: 1.9041834115982055\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 240 loss: 1.7698015451431275\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 250 loss: 1.830757451057434\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 260 loss: 1.7044282793998717\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 270 loss: 1.6803034663200378\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 280 loss: 1.8099231362342834\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 290 loss: 1.8243157863616943\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 300 loss: 1.9057543873786926\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 310 loss: 1.7324877858161927\n",
      "( = 0.07,  = 0.0001)\n",
      "Epoch: 4\n",
      "batch 10 loss: 1.8383518576622009\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 20 loss: 1.7547649502754212\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 30 loss: 1.937778389453888\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 40 loss: 1.7495774507522583\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 50 loss: 1.7247251629829408\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 60 loss: 1.8420005083084106\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 70 loss: 1.695208442211151\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 80 loss: 1.8393190145492553\n",
      "( = 0.07,  = 0.0001)\n",
      "batch 90 loss: 1.7289611935615539\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 100 loss: 1.6454097747802734\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 110 loss: 1.7655576109886169\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 120 loss: 1.7779263496398925\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 130 loss: 1.8017138957977294\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 140 loss: 1.6868077039718627\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 150 loss: 1.7902444124221801\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 160 loss: 1.706954050064087\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 170 loss: 1.7920406103134154\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 180 loss: 1.6683299779891967\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 190 loss: 1.8167321324348449\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 200 loss: 1.7417416095733642\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 210 loss: 1.782376229763031\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 220 loss: 1.7523263216018676\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 230 loss: 1.6404643774032592\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 240 loss: 1.7972594022750854\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 250 loss: 1.7695632219314574\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 260 loss: 1.7419269919395446\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 270 loss: 1.7709725379943848\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 280 loss: 1.6844748616218568\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 290 loss: 1.6607302904129029\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 300 loss: 1.7609578967094421\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 310 loss: 1.697431778907776\n",
      "( = 0.08,  = 0.0001)\n",
      "Epoch: 5\n",
      "batch 10 loss: 1.7183890461921691\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 20 loss: 1.5807299613952637\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 30 loss: 1.7111735343933105\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 40 loss: 1.7889001488685607\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 50 loss: 1.79147367477417\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 60 loss: 1.6894039511680603\n",
      "( = 0.08,  = 0.0001)\n",
      "batch 70 loss: 1.8099594950675963\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 80 loss: 1.7924037337303163\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 90 loss: 1.7295756936073303\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 100 loss: 1.9733915209770203\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 110 loss: 1.7683682918548584\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 120 loss: 1.8684641361236571\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 130 loss: 1.729188370704651\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 140 loss: 1.7300136089324951\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 150 loss: 1.8350766897201538\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 160 loss: 1.8127655148506165\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 170 loss: 1.7736529588699341\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 180 loss: 1.6541729688644409\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 190 loss: 1.6452958226203918\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 200 loss: 1.7631410598754882\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 210 loss: 1.745755660533905\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 220 loss: 1.7794195532798767\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 230 loss: 1.80949923992157\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 240 loss: 1.8405385851860045\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 250 loss: 1.760675048828125\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 260 loss: 1.6616053700447082\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 270 loss: 1.7808841228485108\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 280 loss: 1.682538664340973\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 290 loss: 1.7743668913841248\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 300 loss: 1.6671909928321837\n",
      "( = 0.09,  = 0.0001)\n",
      "batch 310 loss: 1.6490378856658936\n",
      "( = 0.09,  = 0.0001)\n"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    print(f\"Epoch: {1+i}\")\n",
    "    train_one_epoch_dp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DP Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.modules.container.Sequential'>\n"
     ]
    }
   ],
   "source": [
    "print(type(backbone_dp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 848,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the training set: 12.68%\n",
      "Accuracy for label airplane: 97.82%\n",
      "Accuracy for label automobile: 28.92%\n",
      "Accuracy for label bird: 0.00%\n",
      "Accuracy for label cat: 0.00%\n",
      "Accuracy for label deer: 0.00%\n",
      "Accuracy for label dog: 0.02%\n",
      "Accuracy for label frog: 0.00%\n",
      "Accuracy for label horse: 0.02%\n",
      "Accuracy for label ship: 0.00%\n",
      "Accuracy for label truck: 0.02%\n",
      "Accuracy on the training set: 12.68%\n"
     ]
    }
   ],
   "source": [
    "# make sure to modify code to whatever version of model u are testing accuracy for\n",
    "\n",
    "import torch\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# Ensure model in training mode\n",
    "backbone_dp.train()\n",
    "head_dp.train()\n",
    "\n",
    "# Initialize variables\n",
    "correct_predictions = 0\n",
    "total_samples = 0\n",
    "class_correct = [0] * n_classes  \n",
    "class_total = [0] * n_classes\n",
    "\n",
    "# Evaluate the model on the entire dataset\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        images, labels = data\n",
    "        features = backbone_dp(images)\n",
    "        outputs = head_dp(features)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total_samples += labels.size(0)\n",
    "        correct_predictions += (predicted == labels).sum().item()\n",
    "\n",
    "        # Update per-class statistics\n",
    "        for i in range(n_classes):\n",
    "            class_correct[i] += ((predicted == labels) & (labels == i)).sum().item()\n",
    "            class_total[i] += (labels == i).sum().item()\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy = correct_predictions / total_samples\n",
    "print(f\"Accuracy on the training set: {accuracy * 100:.2f}%\")\n",
    "\n",
    "# Calculate accuracy per label\n",
    "for i in range(n_classes):\n",
    "    class_acc = class_correct[i] / class_total[i] if class_total[i] != 0 else 0\n",
    "    print(f\"Accuracy for label {label_names[i]}: {class_acc * 100:.2f}%\")\n",
    "total_samples\n",
    "print(f\"Accuracy on the training set: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(head_dp.state_dict(), '3_head_unbiased.pt')\n",
    "torch.save(backbone_dp.state_dict(), '3_backbone_unbiased.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load trained models!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load 5 models \n",
    "\n",
    "model1 = torchvision.models.resnet18()\n",
    "model1.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "n_features = model1.fc.in_features\n",
    "n_classes = 10\n",
    "model1.fc = torch.nn.Linear(n_features, n_classes)\n",
    "model1_dict = torch.load('model_untrained_1.pt')\n",
    "model1.load_state_dict(model1_dict)\n",
    "model1.eval()\n",
    "\n",
    "\n",
    "\n",
    "model2 = torchvision.models.resnet18()\n",
    "model2.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "n_features = model2.fc.in_features\n",
    "n_classes = 10\n",
    "model2.fc = torch.nn.Linear(n_features, n_classes)\n",
    "model2_dict = torch.load('model_trained_1.pt')\n",
    "model2.load_state_dict(model2_dict)\n",
    "model2.eval()\n",
    "\n",
    "model3 = torchvision.models.resnet18()\n",
    "model3.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "n_features = model3.fc.in_features\n",
    "n_classes = 10\n",
    "model3.fc = torch.nn.Linear(n_features, n_classes)\n",
    "model3_dict = torch.load('model_dp_eps_point1_1.pt')\n",
    "model3.load_state_dict(model3_dict)\n",
    "model3.eval()\n",
    "\n",
    "\n",
    "model4 = torchvision.models.resnet18()\n",
    "model4.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "n_features = model4.fc.in_features\n",
    "n_classes = 10\n",
    "model4.fc = torch.nn.Linear(n_features, n_classes)\n",
    "model4_dict = torch.load('model_dp_eps_5_1.pt')\n",
    "model4.load_state_dict(model4_dict)\n",
    "model4.eval()\n",
    "\n",
    "\n",
    "model5 = torchvision.models.resnet18()\n",
    "model5.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "n_features = model5.fc.in_features\n",
    "n_classes = 10\n",
    "model5.fc = torch.nn.Linear(n_features, n_classes)\n",
    "model5_dict = torch.load('model_dp_eps_25_1.pt')\n",
    "model5.load_state_dict(model5_dict)\n",
    "model5.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load biased models (work in progress)\n",
    "\n",
    "model1b = torchvision.models.resnet18()\n",
    "model1b.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "n_features = model1b.fc.in_features\n",
    "n_classes = 10\n",
    "model1b.fc = torch.nn.Linear(n_features, n_classes)\n",
    "model1b_dict = torch.load('model_untrained_1.pt')\n",
    "model1b.load_state_dict(model1b_dict)\n",
    "model1b.eval()\n",
    "\n",
    "\n",
    "\n",
    "model2b = torchvision.models.resnet18()\n",
    "model2b.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "n_features = model2b.fc.in_features\n",
    "n_classes = 10\n",
    "model2b.fc = torch.nn.Linear(n_features, n_classes)\n",
    "model2b_dict = torch.load('model_trained_biased_1.pt')\n",
    "model2b.load_state_dict(model2b_dict)\n",
    "model2b.eval()\n",
    "\n",
    "model3b = torchvision.models.resnet18()\n",
    "model3b.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "n_features = model3b.fc.in_features\n",
    "n_classes = 10\n",
    "model3b.fc = torch.nn.Linear(n_features, n_classes)\n",
    "model3b_dict = torch.load('model_dp_eps_point1_biased_1.pt')\n",
    "model3b.load_state_dict(model3b_dict)\n",
    "model3b.eval()\n",
    "\n",
    "\n",
    "model4b = torchvision.models.resnet18()\n",
    "model4b.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "n_features = model4b.fc.in_features\n",
    "n_classes = 10\n",
    "model4b.fc = torch.nn.Linear(n_features, n_classes)\n",
    "model4b_dict = torch.load('model_dp_eps_5_biased_1.pt')\n",
    "model4b.load_state_dict(model4b_dict)\n",
    "model4b.eval()\n",
    "\n",
    "\n",
    "model5b = torchvision.models.resnet18()\n",
    "model5b.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "n_features = model5b.fc.in_features\n",
    "n_classes = 10\n",
    "model5b.fc = torch.nn.Linear(n_features, n_classes)\n",
    "model5b_dict = torch.load('model_dp_eps_25_biased_1.pt')\n",
    "model5b.load_state_dict(model5b_dict)\n",
    "model5b.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lime attribution: 100%|| 3/3 [00:00<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attribution range: -0.8874900341033936 to 0.6057196855545044\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# rerun this code based on image you wish to generate explanation for\n",
    "# use prediction dictionaries to find out which image you want to generate explanation for \n",
    "# i.e. dataset[32161] corresponds to an image which was predicted correctly with the non-private model\n",
    "# and incorrectly for the private model\n",
    "cor_incor, label = dataset[32161] \n",
    "cor_incor = cor_incor.squeeze().numpy()\n",
    "create_limeimageexp(model5, cor_incor)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Dictionary work \n",
    "### By evaluating and comparing dictionaries, you can figure out which images are relevant for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 831,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'b' correlated to biased models which is still a work in progress \n",
    "model1b_cor_pred_dict, model1b_incor_pred_dict = create_predictions_dictionaries(model1b)\n",
    "model2b_cor_pred_dict, model2b_incor_pred_dict = create_predictions_dictionaries(model2b)\n",
    "model3b_cor_pred_dict, model3b_incor_pred_dict = create_predictions_dictionaries(model3b)\n",
    "model4b_cor_pred_dict, model4b_incor_pred_dict = create_predictions_dictionaries(model4b)\n",
    "model5b_cor_pred_dict, model5b_incor_pred_dict = create_predictions_dictionaries(model5b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1_cor_pred_dict, model1_incor_pred_dict = create_predictions_dictionaries(model1)\n",
    "model2_cor_pred_dict, model2_incor_pred_dict = create_predictions_dictionaries(model2)\n",
    "model3_cor_pred_dict, model3_incor_pred_dict = create_predictions_dictionaries(model3)\n",
    "model4_cor_pred_dict, model4_incor_pred_dict = create_predictions_dictionaries(model4)\n",
    "model5_cor_pred_dict, model5_incor_pred_dict = create_predictions_dictionaries(model5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 662,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4945, 5014, 39132, 46279, 48036]\n"
     ]
    }
   ],
   "source": [
    "listcor = []\n",
    "listcor.append((model1_pred_dict[1])\n",
    "               \n",
    "print(model1_pred_dict[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharedIncorrectPredsDict = {}\n",
    "for i in range(n_classes):\n",
    "    sharedIncorrectPredsDict[i] = set(model1_incor_pred_dict[i]).intersection(model2_incor_pred_dict[i], model3_incor_pred_dict[i], model4_incor_pred_dict[i], model5_incor_pred_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharedCorrectPredsDict = {}\n",
    "for i in range(n_classes):\n",
    "    sharedCorrectPredsDict[i] = set(model1_pred_dict[i]).intersection(model2_pred_dict[i], model3_pred_dict[i], model4_pred_dict[i], model5_pred_dict[i])\n",
    "\n",
    "sharedCorrectPredsDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "287"
      ]
     },
     "execution_count": 863,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharedCorrectPredsDict_b = {}\n",
    "for i in range(n_classes):\n",
    "    sharedCorrectPredsDict_b[i] = set(model1b_cor_pred_dict[i]).intersection(model2b_cor_pred_dict[i], model3b_cor_pred_dict[i], model4b_cor_pred_dict[i], model5b_cor_pred_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{290,\n",
       " 741,\n",
       " 1183,\n",
       " 1749,\n",
       " 2176,\n",
       " 2388,\n",
       " 2462,\n",
       " 2489,\n",
       " 2577,\n",
       " 3240,\n",
       " 3258,\n",
       " 3425,\n",
       " 4001,\n",
       " 4300,\n",
       " 4718,\n",
       " 4892,\n",
       " 5030,\n",
       " 5304,\n",
       " 5377,\n",
       " 5378,\n",
       " 5675,\n",
       " 5891,\n",
       " 6139,\n",
       " 6322,\n",
       " 6337,\n",
       " 6565,\n",
       " 6717,\n",
       " 6909,\n",
       " 7237,\n",
       " 7281,\n",
       " 8668,\n",
       " 9262,\n",
       " 10268,\n",
       " 10511,\n",
       " 10613,\n",
       " 10638,\n",
       " 10646,\n",
       " 11352,\n",
       " 11593,\n",
       " 12126,\n",
       " 12236,\n",
       " 12268,\n",
       " 12457,\n",
       " 13095,\n",
       " 13109,\n",
       " 13266,\n",
       " 13476,\n",
       " 13616,\n",
       " 13982,\n",
       " 14624,\n",
       " 14693,\n",
       " 14821,\n",
       " 15727,\n",
       " 15951,\n",
       " 16259,\n",
       " 16315,\n",
       " 16435,\n",
       " 16479,\n",
       " 16572,\n",
       " 17010,\n",
       " 17330,\n",
       " 17482,\n",
       " 17516,\n",
       " 17592,\n",
       " 17696,\n",
       " 17962,\n",
       " 18153,\n",
       " 18232,\n",
       " 18307,\n",
       " 18700,\n",
       " 18728,\n",
       " 19195,\n",
       " 19336,\n",
       " 19530,\n",
       " 19648,\n",
       " 19658,\n",
       " 19829,\n",
       " 19836,\n",
       " 20089,\n",
       " 20395,\n",
       " 20620,\n",
       " 20863,\n",
       " 20889,\n",
       " 20898,\n",
       " 20949,\n",
       " 21111,\n",
       " 21257,\n",
       " 21880,\n",
       " 21936,\n",
       " 22096,\n",
       " 23681,\n",
       " 23872,\n",
       " 24164,\n",
       " 24315,\n",
       " 24386,\n",
       " 24740,\n",
       " 24765,\n",
       " 25123,\n",
       " 25412,\n",
       " 26603,\n",
       " 26967,\n",
       " 27783,\n",
       " 27808,\n",
       " 28153,\n",
       " 28682,\n",
       " 29056,\n",
       " 29078,\n",
       " 29239,\n",
       " 29524,\n",
       " 29726,\n",
       " 29991,\n",
       " 30329,\n",
       " 30488,\n",
       " 30997,\n",
       " 31456,\n",
       " 31526,\n",
       " 31563,\n",
       " 31565,\n",
       " 31608,\n",
       " 31697,\n",
       " 32051,\n",
       " 32132,\n",
       " 33695,\n",
       " 34468,\n",
       " 34522,\n",
       " 34636,\n",
       " 34792,\n",
       " 35586,\n",
       " 35985,\n",
       " 36255,\n",
       " 36438,\n",
       " 36804,\n",
       " 37550,\n",
       " 37587,\n",
       " 37633,\n",
       " 37953,\n",
       " 38002,\n",
       " 38045,\n",
       " 38554,\n",
       " 38835,\n",
       " 38862,\n",
       " 39299,\n",
       " 39342,\n",
       " 41002,\n",
       " 41218,\n",
       " 41543,\n",
       " 41616,\n",
       " 41744,\n",
       " 42571,\n",
       " 43001,\n",
       " 43183,\n",
       " 43278,\n",
       " 43334,\n",
       " 44477,\n",
       " 44672,\n",
       " 44720,\n",
       " 45912,\n",
       " 45937,\n",
       " 46504,\n",
       " 46704,\n",
       " 47000,\n",
       " 47373,\n",
       " 47646,\n",
       " 47945,\n",
       " 47971,\n",
       " 48107,\n",
       " 48125,\n",
       " 48445,\n",
       " 48491,\n",
       " 49827,\n",
       " 49851}"
      ]
     },
     "execution_count": 867,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sharedIncorrectPredsDict_b = {}\n",
    "for i in range(n_classes):\n",
    "    sharedIncorrectPredsDict_b[i] = set(model1b_incor_pred_dict[i]).intersection(model2b_incor_pred_dict[i], model3b_incor_pred_dict[i], model4b_incor_pred_dict[i], model5b_incor_pred_dict[i])\n",
    "\n",
    "sharedIncorrectPredsDict_b[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find a sample which gets incorrectly predicted by dp but correctly predicted by non dp and low priv\n",
    "\n",
    "noisedOutSamplesDict = {}\n",
    "for i in range (n_classes):\n",
    "    # list of images which were predicted correctly by non private and incorrectly by high \n",
    "    # privacy model\n",
    "    combined =  [element for element in (model2_cor_pred_dict[i]).intersection(model3_incor_pred_dict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 730,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# quick check , should be 0 \n",
    "print(len(set(sharedIncorrectPredsDict[0].intersection(sharedCorrectPredsDict[0]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spare Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "dataset = datasets.CIFAR10(root=\"cifar\", train=True, download=True, transform=transform)\n",
    "\n",
    "# Define the percentages for each class\n",
    "percentage_from_class = {\n",
    "    0: 0.4,\n",
    "    1: 0.2,\n",
    "    # Remaining classes will get an equal share\n",
    "}\n",
    "\n",
    "subset_indices = []\n",
    "\n",
    "# Iterate over each class\n",
    "for class_label, percentage in percentage_from_class.items():\n",
    "    # Find the indices corresponding to the current class\n",
    "    class_indices = [i for i, (_, label) in enumerate(dataset) if label == class_label]\n",
    "    \n",
    "    # Calculate the number of samples to take from the current class\n",
    "    num_samples_class = int(len(class_indices) * percentage)\n",
    "    \n",
    "    # Take the specified percentage from the current class\n",
    "    subset_indices.extend(class_indices[:num_samples_class])\n",
    "\n",
    "# Create the Subset with the specified indices\n",
    "dataset_mini = Subset(dataset, subset_indices)\n",
    "\n",
    "# Create DataLoader\n",
    "trainloader_mini = DataLoader(dataset_mini, batch_size=32, shuffle=True)\n",
    "\n",
    "# Now, trainloader_mini contains the desired distribution of data from different classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #### Non Fine Tuning #############\n",
    "# resnet model, adjusted for 32x32 CIFAR images images\n",
    "model_dp = torchvision.models.resnet18(pretrained=True)\n",
    "\n",
    "# how does pooling not strip all the information from the image\n",
    "model_dp.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "# what is a \"feature\" in supervised learning, is it just edges, shapes, etc. \n",
    "# how does feature identification differ from identifying clusters in unsupervised learning \n",
    "n_features = model_dp.fc.in_features\n",
    "n_classes = 10\n",
    "model_dp.fc = torch.nn.Linear(n_features, n_classes)\n",
    "\n",
    "from opacus.validators import ModuleValidator\n",
    "\n",
    "errors = ModuleValidator.validate(model_dp, strict=False)\n",
    "errors[-5:]\n",
    "\n",
    "model_dp = ModuleValidator.fix(model_dp)\n",
    "ModuleValidator.validate(model_dp, strict=False)\n",
    "\n",
    "# training  \n",
    "\n",
    "loss_fn_dp = torch.nn.CrossEntropyLoss()\n",
    "optimizer_dp = torch.optim.SGD(model_dp.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "# mini dataset privacy engine\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "privacy_engine = PrivacyEngine()\n",
    "\n",
    "model_dp, optimizer_dp, trainloader_mini = privacy_engine.make_private_with_epsilon(\n",
    "    module=model_dp,\n",
    "    optimizer=optimizer_dp,\n",
    "    data_loader=trainloader_mini,\n",
    "    epochs=EPOCHS,\n",
    "    target_epsilon=EPSILON,\n",
    "    target_delta=DELTA,\n",
    "    max_grad_norm=MAX_GRAD_NORM,\n",
    ")\n",
    "\n",
    "print(f\"Using sigma={optimizer_dp.noise_multiplier} and C={MAX_GRAD_NORM}\")\n",
    "# training using engine and mini dataset (non fine tuning version)\n",
    "\n",
    "def train_one_epoch_dp():\n",
    "    running_loss = 0.0\n",
    "    last_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(trainloader_mini):\n",
    "        \n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer_dp.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model_dp(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn_dp(outputs, labels)\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer_dp.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        if i % 10 == 9:\n",
    "            epsilon = privacy_engine.get_epsilon(DELTA)\n",
    "            last_loss = running_loss / 10  # loss per batch\n",
    "            print(f\"batch {i+1} loss: {last_loss}\")\n",
    "            print(f\"( = {epsilon:.2f},  = {DELTA})\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    print(f\"Epoch: {i+1}\")\n",
    "    train_one_epoch_dp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "dataset = torchvision.datasets.CIFAR10(root=\"cifar\", train=True, download=True, transform=torchvision.transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset, batch_size=32)\n",
    "\n",
    "# resnet model, adjusted for 32x32 CIFAR images images\n",
    "model = torchvision.models.resnet18()\n",
    "\n",
    "model.avgpool = torch.nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "n_features = model.fc.in_features\n",
    "n_classes = 10\n",
    "model.fc = torch.nn.Linear(n_features, n_classes)\n",
    "\n",
    "# training \n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "\n",
    "def train_one_epoch():\n",
    "    running_loss = 0.0\n",
    "    last_loss = 0.0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        # Every data instance is an input + label pair\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Gather data and report\n",
    "        running_loss += loss.item()\n",
    "        if i % 10 == 9:\n",
    "            last_loss = running_loss / 10  # loss per batch\n",
    "            print(f\"batch {i+1} loss: {last_loss}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "train_one_epoch()\n",
    "\n",
    "# save model \n",
    "# torch.save(model.state_dict(), 'model_rml.pt')\n",
    "\n",
    "# load model \n",
    "model_dict = torch.load('model_rml.pt')\n",
    "model.load_state_dict(model_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[364], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m         ax[i]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mind\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m         ax[i]\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mshow_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_idx\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[364], line 4\u001b[0m, in \u001b[0;36mshow_image\u001b[0;34m(ind)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_image\u001b[39m(ind): \n\u001b[0;32m----> 4\u001b[0m     fig, ax \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m6.4\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m4.8\u001b[39m])\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, (name, source) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mImage\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMask\u001b[39m\u001b[38;5;124m'\u001b[39m], [voc_ds\u001b[38;5;241m.\u001b[39mimages, voc_ds\u001b[38;5;241m.\u001b[39mmasks])):\n\u001b[1;32m      6\u001b[0m         ax[i]\u001b[38;5;241m.\u001b[39mimshow(Image\u001b[38;5;241m.\u001b[39mopen(source[ind]));\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "sample_idx = 10\n",
    "\n",
    "def show_image(ind): \n",
    "    fig, ax = plt.subplots(1, 2, figsize=[6.4 * 2, 4.8])\n",
    "    for i, (name, source) in enumerate(zip(['Image', 'Mask'], [voc_ds.images, voc_ds.masks])):\n",
    "        ax[i].imshow(Image.open(source[ind]));\n",
    "        ax[i].set_title(f\"{name} {ind}\")\n",
    "        ax[i].axis('off')\n",
    "\n",
    "show_image(sample_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc_ds = VOCSegmentation(\n",
    "    './VOC',\n",
    "    year='2012',\n",
    "    image_set='train',\n",
    "    download=True,\n",
    "    transform=T.Compose([\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "        )    \n",
    "    ]),\n",
    "    target_transform=T.Lambda(\n",
    "        lambda p: torch.tensor(p.getdata()).view(1, p.size[1], p.size[0])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, seg_mask = voc_ds[sample_idx]  # tensors of shape (channel, hight, width)\n",
    "\n",
    "print(type(img))\n",
    "outputs = model(img.unsqueeze(0))\n",
    "\n",
    "print(type(outputs))\n",
    "output_probs = F.softmax(outputs, dim=1).squeeze(0)\n",
    "\n",
    "seg_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attempt\n",
    "import opacus\n",
    "from opacus import PrivacyEngine\n",
    "\n",
    "\n",
    "privacy_engine = privacy_engine(model_dp, \n",
    "                                      noise_multiplier=0.1, \n",
    "                                      max_grad_norm=MAX_GRAD_NORM, \n",
    "                                      target_delta=1e-5\n",
    ")\n",
    "privacy_engine.attach(optimizer_dp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
